{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "import torchshow as ts\n",
    "import torchmetrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importere dataset, kun træning indtil videre.\n",
    "training_images = MNIST(root='data', transform=ToTensor(), train=True)\n",
    "training_dataloader = DataLoader(training_images, batch_size=1000)\n",
    "testing_images = MNIST(root='data', transform=ToTensor(), train=False)\n",
    "testing_dataloader = DataLoader(testing_images, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laver det Neurale Netværk, og opstiller et accuracy objekt til at måle hvor god modellen er.\n",
    "accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 12, kernel_size=3), #første parameter 1 er antal kanaler, her 1 fordi vi arbejder med gråtoner; 12 er antal ouputkanaler, altså antal filtre; 3 er størrelsen på det udsnit af billedet vi tager, som så bliver 3x3 matrice af pixels.\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2), #vælger den maksimale værdi i et udsnit af størrelsen 2x2, således dimensionerne af dataene reduceres fra 28x28 til 14x14\n",
    "    nn.Conv2d(12, 12, kernel_size=3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2), #vælger den maksimale værdi i et udsnit af størrelsen 2x2, således dimensionerne af dataene reduceres fra 14x14 til 7x7\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(300,12), # input er nu 5 x 5 x 12\n",
    ")\n",
    "# Bruger crossentropy til at udregne losset, og indstiller optimizeren.\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01, maximize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop'er over 10 epoker, og udregner loss'et og accuracy for hvert.\n",
    "def training_loop(training_dataloader, optimizer, loss_fn):\n",
    "    total_loss = 0\n",
    "    accuracy.reset()\n",
    "    size = len(training_dataloader)\n",
    "    for images,labels in training_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = net(images)\n",
    "        loss = loss_fn(output, labels)\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        accuracy.update(output, labels)\n",
    "    avg_loss = total_loss / size\n",
    "    print(f\"Avg Training Accuracy: {accuracy.compute() * 100:.2f}%\")\n",
    "    print(f\"Avg Training Loss: {avg_loss}\")\n",
    "\n",
    "def testing_loop(testing_dataloader, loss_fn):\n",
    "    total_loss = 0\n",
    "    accuracy.reset()\n",
    "    size = len(testing_dataloader)\n",
    "    with torch.no_grad():\n",
    "        for images,labels in testing_dataloader:\n",
    "            output = net(images)\n",
    "            loss = loss_fn(output, labels)\n",
    "            total_loss += loss\n",
    "            accuracy.update(output,labels)\n",
    "    avg_loss = total_loss / size\n",
    "    print(f\"Avg Testing Accuracy: {accuracy.compute() * 100 :.2f}%\")\n",
    "    print(f\"Avg Testing Loss: {avg_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "If `preds` have one dimension more than `target`, `preds.shape[1]` should be equal to number of classes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     testing_loop(testing_dataloader, loss_fn)\n\u001b[1;32m      4\u001b[0m     training_loop(training_dataloader, optimizer, loss_fn)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[49], line 27\u001b[0m, in \u001b[0;36mtesting_loop\u001b[0;34m(testing_dataloader, loss_fn)\u001b[0m\n\u001b[1;32m     25\u001b[0m         loss \u001b[38;5;241m=\u001b[39m loss_fn(output, labels)\n\u001b[1;32m     26\u001b[0m         total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[0;32m---> 27\u001b[0m         accuracy\u001b[38;5;241m.\u001b[39mupdate(output,labels)\n\u001b[1;32m     28\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m total_loss \u001b[38;5;241m/\u001b[39m size\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvg Testing Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;241m.\u001b[39mcompute()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/IntelligentSystems/lib/python3.12/site-packages/torchmetrics/metric.py:550\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad):\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m         update(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    552\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected all tensors to be on\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/IntelligentSystems/lib/python3.12/site-packages/torchmetrics/classification/stat_scores.py:339\u001b[0m, in \u001b[0;36mMulticlassStatScores.update\u001b[0;34m(self, preds, target)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Update state with predictions and targets.\"\"\"\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_args:\n\u001b[0;32m--> 339\u001b[0m     _multiclass_stat_scores_tensor_validation(\n\u001b[1;32m    340\u001b[0m         preds, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultidim_average, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index\n\u001b[1;32m    341\u001b[0m     )\n\u001b[1;32m    342\u001b[0m preds, target \u001b[38;5;241m=\u001b[39m _multiclass_stat_scores_format(preds, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_k)\n\u001b[1;32m    343\u001b[0m tp, fp, tn, fn \u001b[38;5;241m=\u001b[39m _multiclass_stat_scores_update(\n\u001b[1;32m    344\u001b[0m     preds, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_k, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultidim_average, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index\n\u001b[1;32m    345\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/IntelligentSystems/lib/python3.12/site-packages/torchmetrics/functional/classification/stat_scores.py:282\u001b[0m, in \u001b[0;36m_multiclass_stat_scores_tensor_validation\u001b[0;34m(preds, target, num_classes, multidim_average, ignore_index)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf `preds` have one dimension more than `target`, `preds` should be a float tensor.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preds\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m num_classes:\n\u001b[0;32m--> 282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf `preds` have one dimension more than `target`, `preds.shape[1]` should be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m equal to number of classes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m     )\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preds\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;241m!=\u001b[39m target\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf `preds` have one dimension more than `target`, the shape of `preds` should be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (N, C, ...), and the shape of `target` should be (N, ...).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    290\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: If `preds` have one dimension more than `target`, `preds.shape[1]` should be equal to number of classes."
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(f\"Epoch: {i}\")\n",
    "    testing_loop(testing_dataloader, loss_fn)\n",
    "    training_loop(training_dataloader, optimizer, loss_fn)\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string: valid expression required before '}' (4227079096.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[23], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f\"Modul bud: {}\")\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m f-string: valid expression required before '}'\n"
     ]
    }
   ],
   "source": [
    "# Afprøver modellen på et givent index af billederne.\n",
    "img_idx = 1000\n",
    "pred = net(training_images[img_idx][0])\n",
    "print(\"Model output:\")\n",
    "print(pred)\n",
    "sm = nn.Softmax(dim=1)\n",
    "print(\"Efter softmax:\")\n",
    "print(sm(pred))\n",
    "print(f\"Modul bud: {}\")\n",
    "print()\n",
    "ts.show(training_images[img_idx][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IntelligentSystems",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
