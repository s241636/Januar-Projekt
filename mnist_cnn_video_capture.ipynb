{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "import torchshow as ts\n",
    "import torchmetrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importere dataset, kun træning indtil videre.\n",
    "training_images = MNIST(root='data', transform=ToTensor(), train=True)\n",
    "training_dataloader = DataLoader(training_images, batch_size=1000)\n",
    "testing_images = MNIST(root='data', transform=ToTensor(), train=False)\n",
    "testing_dataloader = DataLoader(testing_images, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laver det Neurale Netværk, og opstiller et accuracy objekt til at måle hvor god modellen er.\n",
    "accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 10, kernel_size=3), #første parameter 1 er antal kanaler, her 1 fordi vi arbejder med gråtoner; 12 er antal ouputkanaler, altså antal filtre; 3 er størrelsen på det udsnit af billedet vi tager, som så bliver 3x3 matrice af pixels.\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2), #vælger den maksimale værdi i et udsnit af størrelsen 2x2, således dimensionerne af dataene reduceres fra 28x28 til 14x14\n",
    "    nn.Conv2d(10, 10, kernel_size=3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2), #vælger den maksimale værdi i et udsnit af størrelsen 2x2, således dimensionerne af dataene reduceres fra 14x14 til 7x7\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(250,10), # input er nu 5 x 5 x 10\n",
    ")\n",
    "# Bruger crossentropy til at udregne losset, og indstiller optimizeren.\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01, maximize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop'er over 10 epoker, og udregner loss'et og accuracy for hvert.\n",
    "def training_loop(training_dataloader, optimizer, loss_fn):\n",
    "    total_loss = 0\n",
    "    accuracy.reset()\n",
    "    size = len(training_dataloader)\n",
    "    for images,labels in training_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = net(images)\n",
    "        loss = loss_fn(output, labels)\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        accuracy.update(output, labels)\n",
    "    avg_loss = total_loss / size\n",
    "    print(f\"Avg Training Accuracy: {accuracy.compute() * 100:.2f}%\")\n",
    "    print(f\"Avg Training Loss: {avg_loss}\")\n",
    "\n",
    "def testing_loop(testing_dataloader, loss_fn):\n",
    "    total_loss = 0\n",
    "    accuracy.reset()\n",
    "    size = len(testing_dataloader)\n",
    "    with torch.no_grad():\n",
    "        for images,labels in testing_dataloader:\n",
    "            output = net(images)\n",
    "            loss = loss_fn(output, labels)\n",
    "            total_loss += loss\n",
    "            accuracy.update(output,labels)\n",
    "    avg_loss = total_loss / size\n",
    "    print(f\"Avg Testing Accuracy: {accuracy.compute() * 100 :.2f}%\")\n",
    "    print(f\"Avg Testing Loss: {avg_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(f\"Epoch: {i}\")\n",
    "    testing_loop(testing_dataloader, loss_fn)\n",
    "    training_loop(training_dataloader, optimizer, loss_fn)\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afprøver modellen på et givent index af billederne.\n",
    "img_idx = 10\n",
    "pred = net(training_images[img_idx][0].unsqueeze(0)) \n",
    "print(\"Model output:\")\n",
    "print(pred)\n",
    "sm = nn.Softmax(dim=1)\n",
    "print(\"Efter softmax:\")\n",
    "print(sm(pred))\n",
    "print(f\"Modul bud: {pred.argmax()}\")\n",
    "print()\n",
    "ts.show(training_images[img_idx][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-10 13:15:39.510 python[23077:696934] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Video setup\n",
    "cap = cv2.VideoCapture(0)\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "while True:\n",
    "\n",
    "    _, frame = cap.read()\n",
    "    frame_copy = frame.copy()\n",
    "\n",
    "    bbox_size = (60, 60)\n",
    "\n",
    "    cv2.imshow(\"input\", frame_copy)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-10 13:25:01.180 python[23166:703402] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up figure\n",
    "fig = plt.figure(1)\n",
    "ax = fig.gca()\n",
    "vid = plt.imshow(np.ones((224, 224, 3)))\n",
    "lbl = plt.text(0, 0, \"Loading...\", size=25, va='top')\n",
    "lbl.set_bbox({'facecolor': 'white', 'alpha': 0.5, 'edgecolor': 'none'})\n",
    "ax.set_axis_off()\n",
    "plt.ion()\n",
    "plt.show()\n",
    "\n",
    "# Set up video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "fig.canvas.mpl_connect('close_event', lambda evt: cap.release())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IntelligentSystems",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
